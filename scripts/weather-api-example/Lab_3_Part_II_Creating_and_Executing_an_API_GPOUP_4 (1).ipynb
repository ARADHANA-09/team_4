{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GROUP- 4:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CojT76QDBmhP"
   },
   "source": [
    "# Fetching Weather Data and Uploading to AWS S3\n",
    "\n",
    "This guide provides steps for fetching weather data using the OpenWeatherMap API and then uploading the data to an Amazon S3 bucket using Python.\n",
    "\n",
    "## Step 1: Obtain an API Key from OpenWeatherMap\n",
    "\n",
    "1. Register on the [OpenWeatherMap website](https://openweathermap.org/) and create an account.\n",
    "2. Find and copy the API key from your account dashboard.\n",
    "\n",
    "## Step 2: Write Python Function to Fetch Weather Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "IhtMAOMHBiyt"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def get_weather_data(city, api_key):\n",
    "    base_url = \"https://api.openweathermap.org/data/2.5/weather\"\n",
    "    params = {'q': city, 'appid': api_key}\n",
    "    response = requests.get(base_url, params=params)\n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        raise Exception(\"Failed to fetch weather data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qGIMEi1-Bvbm"
   },
   "source": [
    "## Step 3: Set Up AWS Credentials for S3 Access\n",
    "* Install Boto3 using pip install boto3.\n",
    "* Configure AWS credentials (AWS Access Key ID and Secret Access Key)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lZW3uJbuB489",
    "outputId": "aebe3abe-9c4c-4927-e4d0-b83aba818bf7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: boto3 in f:\\anaconda\\lib\\site-packages (1.34.3)\n",
      "Requirement already satisfied: botocore<1.35.0,>=1.34.3 in f:\\anaconda\\lib\\site-packages (from boto3) (1.34.4)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in f:\\anaconda\\lib\\site-packages (from boto3) (0.10.0)\n",
      "Requirement already satisfied: s3transfer<0.10.0,>=0.9.0 in f:\\anaconda\\lib\\site-packages (from boto3) (0.9.0)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in f:\\anaconda\\lib\\site-packages (from botocore<1.35.0,>=1.34.3->boto3) (2.8.2)\n",
      "Requirement already satisfied: urllib3<2.1,>=1.25.4 in f:\\anaconda\\lib\\site-packages (from botocore<1.35.0,>=1.34.3->boto3) (1.26.16)\n",
      "Requirement already satisfied: six>=1.5 in f:\\anaconda\\lib\\site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.35.0,>=1.34.3->boto3) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install boto3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vnn-pfSWCXfi"
   },
   "source": [
    "## Step 4: Write Python Function to Upload Data to S3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "Ja7gCT4CCVt4"
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "\n",
    "def upload_to_s3(bucket_name, file_name, data):\n",
    "    s3 = boto3.client('s3')\n",
    "    s3.put_object(Bucket=bucket_name, Key=file_name, Body=json.dumps(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G795_fa1CcgS"
   },
   "source": [
    "## Step 5: Combine the Functions in a Script\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qObZbAK8Ce9C",
    "outputId": "05c3b5f4-c8d8-4dc7-9cad-cb833493f762"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data uploaded successfully to S3\n"
     ]
    }
   ],
   "source": [
    "# Main execution\n",
    "api_key = \"a48f684795a45810ddf42c1a544978d7\"   # Replace with your API key\n",
    "city = \"London\"  # Replace with desired city\n",
    "bucket_name = \"aradhanabucket1\"  # Replace with your S3 bucket name\n",
    "file_name = \"weather_data.json\"\n",
    "\n",
    "try:\n",
    "    weather_data = get_weather_data(city, api_key)\n",
    "    upload_to_s3(bucket_name, file_name, weather_data)\n",
    "    print(\"Data uploaded successfully to S3\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0O_jA3tBCVJY"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WlFDrpu_Co3T",
    "outputId": "62eba14a-296a-4d75-b03c-4506d47983fd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'coord': {'lon': 2.3488, 'lat': 48.8534}, 'weather': [{'id': 804, 'main': 'Clouds', 'description': 'overcast clouds', 'icon': '04n'}], 'base': 'stations', 'main': {'temp': 279.76, 'feels_like': 276.92, 'temp_min': 278.39, 'temp_max': 280.47, 'pressure': 1023, 'humidity': 89}, 'visibility': 10000, 'wind': {'speed': 4.12, 'deg': 300}, 'clouds': {'all': 100}, 'dt': 1703041236, 'sys': {'type': 2, 'id': 2041230, 'country': 'FR', 'sunrise': 1703058036, 'sunset': 1703087722}, 'timezone': 3600, 'id': 2988507, 'name': 'Paris', 'cod': 200}\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "api_key = \"a48f684795a45810ddf42c1a544978d7\"  # Replace with your actual API key\n",
    "city = \"Paris\"\n",
    "try:\n",
    "    weather_data = get_weather_data(city, api_key)\n",
    "    print(weather_data)\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment: Groups to Convert JSON to CSV\n",
    "\n",
    "Step 1. Take the JSON output and convert it to a Dataframe using pandas\n",
    "Step 2. Now upload the CSV file to the 'lab-03' S3 bucket in the cloud with the following naming convention: <your group name>_weather_date_london_<datetimestamp>.csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file 'weather_date_paris.csv' uploaded to S3 bucket 'aradhanabucket1'\n"
     ]
    }
   ],
   "source": [
    "###### INSERT CODE BELOW ####\n",
    "import pandas as pd\n",
    "import json\n",
    "import boto3\n",
    "from datetime import datetime\n",
    "\n",
    "# Step 1: Convert JSON to DataFrame using pandas\n",
    "json_data = '{\"coord\": {\"lon\": 2.3488, \"lat\": 48.8534}, \"weather\": [{\"id\": 804, \"main\": \"Clouds\", \"description\": \"overcast clouds\", \"icon\": \"04n\"}], \"base\": \"stations\", \"main\": {\"temp\": 279.76, \"feels_like\": 276.92, \"temp_min\": 278.39, \"temp_max\": 280.47, \"pressure\": 1023, \"humidity\": 89}, \"visibility\": 10000, \"wind\": {\"speed\": 4.12, \"deg\": 300}, \"clouds\": {\"all\": 100}, \"dt\": 1703041236, \"sys\": {\"type\": 2, \"id\": 2041230, \"country\": \"FR\", \"sunrise\": 1703058036, \"sunset\": 1703087722}, \"timezone\": 3600, \"id\": 2988507, \"name\": \"Paris\", \"cod\": 200}'\n",
    "\n",
    "# Load JSON data into a DataFrame\n",
    "df = pd.json_normalize(json.loads(json_data))\n",
    "\n",
    "# Add a new column 'weather_date' with the current date in the specified format\n",
    "df['weather_date'] = datetime.now().strftime('%Y-%m-%d')\n",
    "\n",
    "# Step 2: Upload the DataFrame to S3 as a CSV file\n",
    "api_key = \"24769bfc5ff7afb25f6cc9aedb2de44d\"   # Replace with your OpenWeatherMap API key\n",
    "bucket_name = \"aradhanabucket1\"  # Replace with your S3 bucket name\n",
    "file_name = f\"weather_date_paris.csv\"\n",
    "\n",
    "# Save DataFrame to CSV\n",
    "df.to_csv(file_name, index=False)\n",
    "\n",
    "# Upload CSV to S3\n",
    "s3 = boto3.client('s3', aws_access_key_id='AKIAQKC4WIR6EJSQZJC3', aws_secret_access_key='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')\n",
    "s3.upload_file(file_name, bucket_name, file_name)\n",
    "\n",
    "print(f\"CSV file '{file_name}' uploaded to S3 bucket '{bucket_name}'\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### END CODE ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
